# Load necessary libraries
library(CovTools) 
library(lsbclust)
library(shapes)
library(ICtest)
library(ggplot2)
library(dplyr)
library(parallel)
library(purrr)
library(Rcpp)

### This is a way to generate data (corr and Cov)

generate_matrices <- function(sample_size,dim,mu,sig) {
  
  replicate(sample_size, {
    
    U <- rorth(dim)
    D <- diag(exp(rnorm(dim,mu,sig)))
    S <- U%*%D%*%t(U)
    
    ## if you want to generate corr matrices, then run the code lines below
    # diagS <- diag(S)
    # diag(1/sqrt(diagS))%*%S%*%diag(1/sqrt(diagS))
    
  })
  
}

matrices <- generate_matrices(5,3,0,1)



# Step 2: Compute average squared distance using distcov
average_squared_distances <- function(matrices) {
  n <- dim(matrices)[3]
  sapply(1:n, function(i) {
    mean(sapply(1:n,
                function(j) if (i != j) distcov(matrices[, , i],
                                                matrices[, , j],
                                                method ='LogEuclidean')^2 else 0))
  })
}



# Step 3: Invert all generated matrices
invert_matrices <- function(matrices) {
  n <- dim(matrices)[3] # Number of matrices
  dim <- dim(matrices)[1] # Dimension of each matrix
  inverted_matrices <- array(0, dim = c(dim, dim, n)) # Create an empty 3D array
  for (i in 1:n) {
    inverted_matrices[, , i] <- solve(matrices[, , i]) # Invert each matrix
  }
  return(inverted_matrices)
}

# Step 4: Compute average squared distance for inverted matrices
average_squared_distances_inverted <- function(matrices) {
  iverted_matrices <- invert_matrices(matrices)
  n <- dim(matrices)[3]
  sapply(1:n, function(i) {
    mean(sapply(1:n, function(j) distcov(matrices[, , i], iverted_matrices[, , j],
                                         method ='LogEuclidean')^2))
  })
}



# --------------------------------------------------------
# Function to compute skewness
# --------------------------------------------------------

metric_skew_fun <- function(matrices) {
  
  # Step 2: Compute average squared distance for original matrices
  avg_dist_original <- average_squared_distances(matrices)
  
  
  # Step 3: Compute average squared distance for inverted matrices
  avg_dist_inverted <- average_squared_distances_inverted(matrices)
  
  # Step 4: Compute the final average squared distance
  final_avg_distance <- mean((avg_dist_original - avg_dist_inverted)^2)/mean(avg_dist_original^2)
  
  # Return results
  return(Metric_skewness = final_avg_distance)
}




Perm_test <- function(matrices, iter, seed, regularize){
  
  
  set.seed(seed)
  
  
  
  # Compute the observed Metric Skewness
  T0 <- metric_skew_fun(matrices)
  
  n <- dim(matrices)[3]
  Tperm <- numeric(iter)
  
  for(b in 1:iter) {
    # random flips: TRUE = invert, FALSE = keep
    flips <- sample(c(TRUE, FALSE), n, replace = TRUE)
    perm_sample <- array(0, dim = dim(matrices))
    for(i in 1:n) {
      if(flips[i]) {
        A <- matrices[,,i]
        if(regularize > 0) A <- A + regularize * diag(dim(generate_matrices(sample_size, dim, mu, sig))[1])
        perm_sample[,,i] <- solve(A)
      } else {
        perm_sample[,,i] <- matrices[,,i]
      }
    }
    Tperm[b] <- metric_skew_fun(perm_sample)
  }

  
  
  
  pval <- mean(abs(Tperm) >= abs(T0))
  
  result <-list(statistic = T0, p.value = pval, Tperm = Tperm)
  names(result) <- c("observed statistic","p_value", "permutation stats")
  result
}


Perm_test(matrices,20,2,0)


# -----------------------------
# 6) Simulation across sample sizes to estimate level
# -----------------------------
estimate_level_over_nsamples <- function(sample_sizes,
                                         dim,
                                         mu, sig,
                                         nrep, iter,
                                         alpha,
                                         regularize,
                                         seed) {
  proportions <- numeric(length(sample_sizes))
  for(k in seq_along(sample_sizes)) {
    n <- sample_sizes[k]
    rejections <- 0
    for(rep in 1:nrep) {
      mat <- generate_matrices(n, dim, mu, sig)
      test <- Perm_test(mat, iter, seed, regularize)
      if(test$p_value < alpha) rejections <- rejections + 1
    }
    proportions[k] <- rejections / nrep
    cat(sprintf("n=%d  -> rejection prop = %.3f\n", n, proportions[k]))
  }
  list(sample_sizes = sample_sizes, proportions = proportions)
}






# -----------------------------
# 7) Run a small experiment (example)
# -----------------------------
seed <- set.seed(2025)
sample_sizes <- seq(10, 200, by = 20)
sample_sizes <- c(2,5,10,20)

res <- estimate_level_over_nsamples(sample_sizes,
                                    dim = 4,
                                    mu = 0, sig = 1,
                                    nrep = 10,   # raise to 200+ for stable estimates
                                    iter = 10,    # increase B for smoother p-values
                                    alpha = 0.05,
                                    regularize = 0,
                                    seed)

# -----------------------------
# 8) Plot results
# -----------------------------
plot(res$sample_sizes, res$proportions, type = "b", pch = 19,
     xlab = "Sample size (number of matrices)",
     ylab = "Proportion p < alpha",
     main = "Level of permutation test (mu = 0)")
abline(h = 0.05, col = "red", lty = 2)





############## Asymptotic test ###########################
distance_matrix <- function(mats) {
  n <- dim(mats)[3]
  D <- matrix(0, n, n)
  
  for (i in 1:(n - 1)) {
    for (j in (i + 1):n) {
      d2 <- distcov(
        mats[, , i],
        mats[, , j],
        method = "LogEuclidean"
      )^2
      
      D[i, j] <- d2
      D[j, i] <- d2
    }
  }
  
  D
}

distance_matrix_to_inverse <- function(mats) {
  inv_mats <- invert_matrices(mats)
  n <- dim(mats)[3]
  
  Dinv <- matrix(0, n, n)
  
  for (i in 1:n) {
    Xi <- mats[, , i]
    for (j in 1:n) {
      Dinv[i, j] <-
        distcov(Xi, inv_mats[, , j],
                method = "LogEuclidean")^2
    }
  }
  
  Dinv
}



# distance_matrix <- function(mats) {
#   n <- dim(mats)[3]
#   
#   D2 <- sapply(seq_len(n), function(i) {
#     sapply(seq_len(n), function(j) {
#       if (i != j) {
#         distcov(mats[, , i],
#                 mats[, , j],
#                 method = "LogEuclidean")^2
#       } else {
#         0
#       }
#     })
#   })
#   
#   return(D2)
# }



# distance_matrix_fast <- function(mats) {
#   n <- dim(mats)[3]
#   D <- matrix(0, n, n)
#   
#   idx <- which(upper.tri(D), arr.ind = TRUE)
#   
#   for (m in seq_len(nrow(idx))) {
#     i <- idx[m, 1]
#     j <- idx[m, 2]
#     
#     d2 <- distcov(
#       mats[, , i],
#       mats[, , j],
#       method = "LogEuclidean"
#     )^2
#     
#     D[i, j] <- d2
#     D[j, i] <- d2
#   }
#   
#   D
# }





u1_statistic <- function(D) {
  n <- nrow(D)
  total <- 0
  
  for (i in 1:(n - 2)) {
    for (j in (i + 1):(n - 1)) {
      Dij <- D[i, j]
      
      for (k in (j + 1):n) {
        Dik <- D[i, k]
        Djk <- D[j, k]
        
        total <- total +
          Dij * Dik +
          Djk * Dij +
          Dik * Djk
      }
    }
  }
  
  total / (3 * choose(n, 3))
}

u1_statistic(D)


u2_statistic <- function(D, G) {
  n <- nrow(D)
  total <- 0
  
  if (n < 3) {
    stop("U2 statistic requires at least n >= 3 observations.")
  }
  
  stopifnot(
    is.matrix(D), is.matrix(G),
    nrow(D) == ncol(D),
    nrow(G) == ncol(G),
    nrow(D) == nrow(G)
  )
  
  total <- 0
  
  
  for (i in 1:(n - 2)) {
    for (j in (i + 1):(n - 1)) {
      Dij <- D[i, j] - G[i, j]
      
      for (k in (j + 1):n) {
        Dik <- D[i, k] - G[i, k]
        Djk <- D[j, k] - G[j, k]
        
        total <- total +
          Dij * Dik +   # r(i, j, k)
          Djk * Dij +   # r(j, k, i)
          Dik * Djk     # r(k, i, j)
      }
    }
  }
  
  total / (3 * choose(n, 3))
}




asymptotic_metric_skewness <- function(D, G) {
  n <- nrow(D)
  
  # U-statistics of order 3 require n >= 3
  if (n < 3) return(NA_real_)
  
  U1 <- u1_statistic(D)
  U2 <- u2_statistic(D, G)
  
  # Guard against division by zero or numerical degeneracy
  if (!is.finite(U1) || abs(U1) < .Machine$double.eps) {
    return(NA_real_)
  }
  
  U2 / U1
}


set.seed(1)

n   <- 3
dim <- 5
mu  <- 0
sig <- 0.5

mats <- generate_matrices(n, dim, mu, sig)

D <- distance_matrix(mats)
G <- distance_matrix_to_inverse(mats)

u1_statistic(D)
u2_statistic(D,G)

metric_skew_asym <- asymptotic_metric_skewness(D, G)
metric_skew_asym




####

s1_kernel <- function(j, k, l, D) {
  (D[j, k] * D[j, l] +
     D[k, l] * D[k, j] +
     D[l, j] * D[l, k]) / 3
}

s2_kernel <- function(j, k, l, D, G) {
  r_jkl <- (D[j, k] - G[j, k]) * (D[j, l] - G[j, l])
  r_klj <- (D[k, l] - G[k, l]) * (D[k, j] - G[k, j])
  r_ljk <- (D[l, j] - G[l, j]) * (D[l, k] - G[l, k])
  
  (r_jkl + r_klj + r_ljk) / 3
}



s_hat_j <- function(j, D, G, p) {
  n <- nrow(D)
  
  if (n < 3) return(NA_real_)
  
  idx <- setdiff(seq_len(n), j)
  denom <- choose(n - 1, 2)
  total <- 0
  
  for (a in 1:(length(idx) - 1)) {
    for (b in (a + 1):length(idx)) {
      k <- idx[a]
      l <- idx[b]
      
      if (p == 1) {
        total <- total + s1_kernel(j, k, l, D)
      } else if (p == 2) {
        total <- total + s2_kernel(j, k, l, D, G)
      }
    }
  }
  
  total / denom
}


s_hat_vector <- function(D, G, p) {
  n <- nrow(D)
  
  vapply(
    seq_len(n),
    function(j) s_hat_j(j, D, G, p),
    numeric(1)
  )
}


sigma_hat <- function(D, G) {
  n <- nrow(D)
  
  if (n < 3) return(matrix(NA_real_, 2, 2))
  
  s1 <- s_hat_vector(D, p = 1)
  s2 <- s_hat_vector(D, G, p = 2)
  
  s1c <- s1 - mean(s1)
  s2c <- s2 - mean(s2)
  
  sigma <- matrix(0, 2, 2)
  
  sigma[1, 1] <- mean(s1c * s1c)
  sigma[1, 2] <- mean(s1c * s2c)
  sigma[2, 1] <- sigma[1, 2]
  sigma[2, 2] <- mean(s2c * s2c)
  
  sigma
}


D <- distance_matrix_fast(mats)
G <- distance_matrix_to_inverse(mats)

sigma_hat(D, G)









